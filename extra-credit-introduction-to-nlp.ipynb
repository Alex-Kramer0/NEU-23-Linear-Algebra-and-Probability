{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPz5eydmNJ7woC3yH0T6COc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alex-Kramer0/DS5020/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Alex Kramer | Spring 2023 | Probability & Statistics| NLP Extra Credit Assignment**\n",
        "\n",
        "Natural Language Processing (NLP) is a branch of data science/AI that deals with analyzing text and language data. The goal of this assignment will be to build a simple language model and gain insight into the application of probability to text data.\n",
        "\n",
        "First, read the attached section taken from “Speech and Language Processing '' by Jurafsky, which introduces counting words, calculating joint probability of sentences, and N-grams. In class we covered counting, conditional probabilities, and discrete distributions. This section also introduces a new concept of Markov approximations. \n",
        "\n",
        "The first part of this assignment will require you to load and tokenize the text dataset. We will use the same dataset as in the chapter- the Berkeley Restaurant dataset. You can use python\n",
        "packages to achieve this (e.g. nltk).\n",
        "\n",
        "The main steps of the assignments:\n",
        "1. Pre-process and tokenize the dataset provided. Only keep actual words and remove disfluencies such as “uh”, “uhm”. Add special tokens to indicate beginning of each sentence (e.g. </s>)\n",
        "2. Count the words and report the size of your vocabulary. Also report the number of sentences.\n",
        "3. Read the book chapter on N-grams and re-generate figures 4.1 and 4.2 for bigram counts. It doesn’t have to be exact.\n",
        "4. Calculate the joint probability for at least 5 sentences (with vocabulary in the dataset)\n",
        "using bigrams.\n",
        "5. Submit the code or pdf of your program and output. If we can’t run the program, no credit will be assigned."
      ],
      "metadata": {
        "id": "iQQ-C_L03lQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import binary_search_file\n",
        "import re\n",
        "import pandas as pd\n",
        "from nltk import ngrams\n",
        "\n",
        "def line_cleaner(line):\n",
        "    line = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", line)\n",
        "    line = re.sub('[^a-zA-Z ]+','', line)\n",
        "\n",
        "\n",
        "    line = line.split(' ')\n",
        "    line.insert(0, '</s>')\n",
        "    line.pop(1)\n",
        "    while '' in line:\n",
        "      line.remove('')\n",
        "    return line\n",
        "\n",
        "def vocabulary(text):\n",
        "  vocab = []\n",
        "  for lis in text:\n",
        "    # loop through first list\n",
        "    for item in lis:\n",
        "      # loop through items in the list\n",
        "      if item not in vocab:\n",
        "        vocab.append(item)\n",
        "  return vocab\n",
        "\n",
        "def word_count(text):\n",
        "  counter = 0\n",
        "  l = []\n",
        "  sentence = ['i', 'want', 'to', 'eat', 'chinese', 'food', 'lunch', 'spend'] \n",
        "  for word in sentence:\n",
        "    for line in text:\n",
        "      for item in line:\n",
        "        if word == item:\n",
        "          counter += 1\n",
        "    l.append(word)\n",
        "    l.append(counter)  \n",
        "  counter =0\n",
        "  return(l)\n",
        "\n",
        "def bigram(text):\n",
        "  x = []\n",
        "  for line in text:\n",
        "      counter = 0\n",
        "      bi = ngrams(line, 2)\n",
        "      for grams in bi:\n",
        "        x.append(grams)\n",
        "  return x\n",
        "\n",
        "def check_bi(bigram):\n",
        "  sentence = ['i', 'want', 'to', 'eat', 'chinese', 'food', 'lunch', 'spend'] \n",
        "  x =[]\n",
        "  for tup in bigram:\n",
        "    counter = 0\n",
        "    for i in range(len(tup)-1):\n",
        "      if tup[i] in sentence and tup[i+1] in sentence:\n",
        "        x.append(tup)\n",
        "\n",
        "  dictionary = {}\n",
        "  for item in x:\n",
        "    if item not in dictionary:\n",
        "      dictionary[item] = 1\n",
        "    elif item in dictionary:\n",
        "      dictionary[item] += 1\n",
        "\n",
        "  return dictionary\n",
        "\n",
        "\n",
        "\n",
        "def trigram(text):\n",
        "  x = []\n",
        "  for line in text:\n",
        "      counter = 0\n",
        "      tri = ngrams(line, 3)\n",
        "      for grams in tri:\n",
        "        x.append(grams)\n",
        "  return x\n",
        "\n",
        "def check_tri(trigram):\n",
        "  sentence = ['i', 'want', 'to', 'eat', 'chinese', 'food', 'lunch', 'spend'] \n",
        "  x =[]\n",
        "  for tup in trigram:\n",
        "    counter = 0\n",
        "    for i in range(len(tup)-2):\n",
        "      if tup[i] in sentence and tup[i+1] in sentence and tup[i+2] in sentence:\n",
        "        x.append(tup)\n",
        "  \n",
        "  dictionary = {}\n",
        "  for item in x:\n",
        "    if item not in dictionary:\n",
        "      dictionary[item] = 1\n",
        "    elif item in dictionary:\n",
        "      dictionary[item] += 1\n",
        "\n",
        "  return dictionary\n",
        "\n",
        "def normalization(dictionary, ):\n",
        "  pass\n",
        "  for item in dictionary:\n",
        "    item[dictionary.values]\n",
        "\n",
        "def main():\n",
        "  data = open('dataset-1 (1).txt', \"r\")\n",
        "  # open the file\n",
        "  text = []\n",
        "  sentence_count = 0\n",
        "  for line in data:\n",
        "    text.append(line_cleaner(line))\n",
        "    # clean the text data\n",
        "    sentence_count += 1\n",
        "  #print(text)\n",
        "\n",
        "  print('Sentence Count: ', sentence_count)\n",
        "\n",
        "  vocab_list = vocabulary(text)\n",
        "  print('Vocabulary Size: ', len(vocab_list) - 1)\n",
        "  print('')\n",
        "  print('')\n",
        "\n",
        "  bi = bigram(text)\n",
        "\n",
        "  bi_dict = check_bi(bi)\n",
        "  print('Printing Unformatted Table 4.1: ', bi_dict)\n",
        "  \n",
        "  print('')\n",
        "\n",
        "  print('Figure 4.1: shows the bigram counts; hard coded the unformatted table 4.1 into a table for easier grading.')\n",
        "  print('Table below will not update. Unformatted table 4.1 will update and change.')\n",
        "  table = [\n",
        "      [8, 915, 0, 13, 0, 0,0, 2],\n",
        "      [5, 0, 684, 1, 7, 6, 0, 1],\n",
        "      [1, 0, 5, 765, 3, 0, 6, 233],\n",
        "      [1, 0, 0, 0, 18, 2, 53, 0],\n",
        "      [4, 0,0,0,0, 100, 0,0],\n",
        "      [19, 0, 15, 0, 2, 4, 0, 0,],\n",
        "      [2, 0, 1, 0, 1, 1, 0, 0],\n",
        "      [1, 0, 1, 0, 0 , 0, 0, 0]\n",
        "           ]\n",
        "  tb_41 = pd.DataFrame(table, columns = ['i', 'want', 'to', 'eat', 'chinese', 'food', 'lunch', 'spend'], index=['i', 'want', 'to', 'eat', 'chinese', 'food', 'lunch', 'spend'])\n",
        "  print(tb_41)\n",
        "  print('')\n",
        "  print('')\n",
        "\n",
        "  norm = word_count(text)\n",
        "  print('Figure 4.21: Normalization Divisors (Small Table): ', norm)\n",
        "  print('')\n",
        "  print('')\n",
        "\n",
        "  print('Figure 4.2: Shows the bigram probabilties after normalization')\n",
        "  print('dividing each row by the following unigram counts (above)')\n",
        "  print('Hard coded from unformatted table 4.1 & 4.2 into a table for easier grading.')\n",
        "\n",
        "  table2 = [\n",
        "      [8/2847, 915/2847, 0/2847, 13/2847, 0/2847, 0/2847, 0/2847, 2/2847],\n",
        "      [5/3890, 0/3890, 684/3890, 1/3890, 7/3890, 6/3890, 0/3890, 1/3890],\n",
        "      [1/6622, 0/6622, 5/6622, 765/6622, 3/6622, 0/6622, 6/6622, 233/6622],\n",
        "      [1/7455, 0/7455, 0/7455, 0/7455, 18/7455, 2/7455, 53/7455, 0/7455],\n",
        "      [4/7648, 0/7648,0/7648,0/7648,0/7648, 100/7648, 0/7648,0/7648],\n",
        "      [19/8893, 0/8893, 15/8893, 0/8893, 2/8893, 4/8893, 0/8893, 0/8893],\n",
        "      [2/9285, 0/9285, 1/9285, 0/9285, 1/9285, 1/9285, 0/9285, 0/9285],\n",
        "      [1/9596, 0/9596, 1/9596, 0/9596, 0/9596, 0/9596, 0/9596, 0/9596]\n",
        "           ]\n",
        "  tb_421 = pd.DataFrame(table2, columns = ['i', 'want', 'to', 'eat', 'chinese', 'food', 'lunch', 'spend'], index=['i', 'want', 'to', 'eat', 'chinese', 'food', 'lunch', 'spend'])\n",
        "  print(tb_421)\n",
        "  print('')\n",
        "  print('')\n",
        "\n",
        "  print('Calculating Joint Probabilities for 5 Sentences Using Table 4.2 Above')\n",
        "  print('')\n",
        "\n",
        "  print('P(I want to eat lunch)')\n",
        "  print('P(i|<s>)P(want|i)P(to|want)P(eat|to)P(lunch|eat)= 0.25 * 0.3213 * 0.1758 * 0.1155 * 0.0071')\n",
        "  print('=', 0.25 * 0.3213 * 0.1758 * 0.1155 * 0.0071, 'or', 0.25 * 0.3213 * 0.1758 * 0.1155 * 0.0071 * 100, \"%\")\n",
        "  print('')\n",
        "\n",
        "  print('P(I want to eat food)')\n",
        "  print('P(i|<s>)P(want|i)P(to|want)P(eat|to)P(food|eat)= 0.25 * 0.3213 * 0.1758 * 0.1155 * 0.000268')\n",
        "  print('=', 0.25 * 0.3213 * 0.1758 * 0.1155 * 0.000268, 'or', 0.25 * 0.3213 * 0.1758 * 0.1155 * 0.000268 * 100, \"%\")\n",
        "  print('')\n",
        "\n",
        "  print('P(I eat Chinese food)')\n",
        "  print('P(i|<s>)P(eat|i)P(Chinese|eat)P(food|Chinese)= 0.25 * 0.004566 * 0.002414 * 0.013')\n",
        "  print('=', 0.25 * 0.004566 * 0.002414 * 0.013, 'or', 0.25 * 0.004566 * 0.002414 * 0.013* 100, \"%\")\n",
        "  print('')\n",
        "\n",
        "\n",
        "  print('P(I eat food)')\n",
        "  print('P(i|<s>)P(eat|i)P(food|eat)= 0.25 * 0.004566 * 0.000268')\n",
        "  print('=',0.25 * 0.004566 * 0.000268 , 'or',0.25 * 0.004566 * 0.000268 * 100, \"%\")\n",
        "  print('')\n",
        "\n",
        "  print('P(I eat lunch)')\n",
        "  print('P(i|<s>)P(eat|i)P(lunch|eat)= 0.25 * 0.004566 * 0.007109')\n",
        "  print('=',0.25 * 0.004566 * 0.007109 , 'or',0.25 * 0.004566 * 0.007109 * 100, \"%\")\n",
        "  print('')\n",
        "\n",
        "\n",
        "  tri = trigram(text)\n",
        "  tri_dict = check_tri(tri)\n",
        "  print('Unable to print a formatted table for Trigrams')\n",
        "  print('Printing Unformatted Tri 5.11 Table: ', tri_dict)\n",
        "  print('')\n",
        "\n",
        "  print('Trigrams change our calculations greatly. We have completely different probabilities, because we are including an entire extra string.')\n",
        "  print('This change has dropped down the frequency of words occuring together.')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()\n",
        "\n",
        "\n",
        "\n",
        "    \n"
      ],
      "metadata": {
        "id": "lE2PU2GK4LRc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5682aaa6-4381-46a9-cd75-0945dc3b5e6a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence Count:  8566\n",
            "Vocabulary Size:  1660\n",
            "\n",
            "\n",
            "Printing Unformatted Table 4.1:  {('i', 'want'): 915, ('want', 'to'): 684, ('to', 'eat'): 765, ('eat', 'i'): 1, ('to', 'spend'): 233, ('eat', 'lunch'): 53, ('i', 'i'): 8, ('food', 'to'): 15, ('chinese', 'food'): 100, ('to', 'i'): 1, ('lunch', 'to'): 1, ('spend', 'to'): 1, ('food', 'i'): 19, ('i', 'eat'): 13, ('eat', 'chinese'): 18, ('to', 'chinese'): 3, ('to', 'to'): 5, ('to', 'lunch'): 6, ('eat', 'to'): 3, ('want', 'i'): 5, ('spend', 'i'): 1, ('want', 'spend'): 1, ('i', 'spend'): 2, ('want', 'chinese'): 7, ('food', 'food'): 4, ('lunch', 'i'): 2, ('lunch', 'food'): 1, ('chinese', 'lunch'): 1, ('want', 'food'): 6, ('want', 'lunch'): 6, ('eat', 'food'): 2, ('want', 'eat'): 1, ('food', 'chinese'): 2, ('chinese', 'i'): 4}\n",
            "\n",
            "Figure 4.1: shows the bigram counts; hard coded the unformatted table 4.1 into a table for easier grading.\n",
            "Table below will not update. Unformatted table 4.1 will update and change.\n",
            "          i  want   to  eat  chinese  food  lunch  spend\n",
            "i         8   915    0   13        0     0      0      2\n",
            "want      5     0  684    1        7     6      0      1\n",
            "to        1     0    5  765        3     0      6    233\n",
            "eat       1     0    0    0       18     2     53      0\n",
            "chinese   4     0    0    0        0   100      0      0\n",
            "food     19     0   15    0        2     4      0      0\n",
            "lunch     2     0    1    0        1     1      0      0\n",
            "spend     1     0    1    0        0     0      0      0\n",
            "\n",
            "\n",
            "Figure 4.21: Normalization Divisors (Small Table):  ['i', 2847, 'want', 3890, 'to', 6622, 'eat', 7455, 'chinese', 7648, 'food', 8893, 'lunch', 9285, 'spend', 9596]\n",
            "\n",
            "\n",
            "Figure 4.2: Shows the bigram probabilties after normalization\n",
            "dividing each row by the following unigram counts (above)\n",
            "Hard coded from unformatted table 4.1 & 4.2 into a table for easier grading.\n",
            "                i      want        to       eat   chinese      food     lunch  \\\n",
            "i        0.002810  0.321391  0.000000  0.004566  0.000000  0.000000  0.000000   \n",
            "want     0.001285  0.000000  0.175835  0.000257  0.001799  0.001542  0.000000   \n",
            "to       0.000151  0.000000  0.000755  0.115524  0.000453  0.000000  0.000906   \n",
            "eat      0.000134  0.000000  0.000000  0.000000  0.002414  0.000268  0.007109   \n",
            "chinese  0.000523  0.000000  0.000000  0.000000  0.000000  0.013075  0.000000   \n",
            "food     0.002137  0.000000  0.001687  0.000000  0.000225  0.000450  0.000000   \n",
            "lunch    0.000215  0.000000  0.000108  0.000000  0.000108  0.000108  0.000000   \n",
            "spend    0.000104  0.000000  0.000104  0.000000  0.000000  0.000000  0.000000   \n",
            "\n",
            "            spend  \n",
            "i        0.000702  \n",
            "want     0.000257  \n",
            "to       0.035186  \n",
            "eat      0.000000  \n",
            "chinese  0.000000  \n",
            "food     0.000000  \n",
            "lunch    0.000000  \n",
            "spend    0.000000  \n",
            "\n",
            "\n",
            "Calculating Joint Probabilities for 5 Sentences Using Table 4.2 Above\n",
            "\n",
            "P(I want to eat lunch)\n",
            "P(i|<s>)P(want|i)P(to|want)P(eat|to)P(lunch|eat)= 0.25 * 0.3213 * 0.1758 * 0.1155 * 0.0071\n",
            "= 1.1580036756750002e-05 or 0.0011580036756750002 %\n",
            "\n",
            "P(I want to eat food)\n",
            "P(i|<s>)P(want|i)P(to|want)P(eat|to)P(food|eat)= 0.25 * 0.3213 * 0.1758 * 0.1155 * 0.000268\n",
            "= 4.3710561279000004e-07 or 4.3710561279e-05 %\n",
            "\n",
            "P(I eat Chinese food)\n",
            "P(i|<s>)P(eat|i)P(Chinese|eat)P(food|Chinese)= 0.25 * 0.004566 * 0.002414 * 0.013\n",
            "= 3.5822552999999996e-08 or 3.5822552999999996e-06 %\n",
            "\n",
            "P(I eat food)\n",
            "P(i|<s>)P(eat|i)P(food|eat)= 0.25 * 0.004566 * 0.000268\n",
            "= 3.05922e-07 or 3.0592199999999995e-05 %\n",
            "\n",
            "P(I eat lunch)\n",
            "P(i|<s>)P(eat|i)P(lunch|eat)= 0.25 * 0.004566 * 0.007109\n",
            "= 8.1149235e-06 or 0.00081149235 %\n",
            "\n",
            "Unable to print a formatted table for Trigrams\n",
            "Printing Unformatted Tri 5.11 Table:  {('i', 'want', 'to'): 585, ('to', 'eat', 'i'): 1, ('want', 'to', 'spend'): 114, ('to', 'eat', 'lunch'): 46, ('want', 'to', 'eat'): 240, ('food', 'i', 'eat'): 1, ('to', 'eat', 'chinese'): 17, ('eat', 'chinese', 'food'): 17, ('want', 'to', 'to'): 1, ('to', 'to', 'eat'): 4, ('to', 'eat', 'to'): 3, ('i', 'want', 'i'): 3, ('want', 'i', 'want'): 2, ('to', 'spend', 'i'): 1, ('i', 'want', 'spend'): 1, ('to', 'chinese', 'food'): 1, ('i', 'want', 'chinese'): 4, ('want', 'chinese', 'food'): 5, ('food', 'food', 'food'): 1, ('food', 'i', 'want'): 9, ('i', 'i', 'want'): 2, ('i', 'want', 'food'): 6, ('want', 'i', 'i'): 1, ('i', 'want', 'lunch'): 6, ('to', 'eat', 'food'): 2, ('eat', 'to', 'eat'): 2, ('i', 'want', 'eat'): 1, ('want', 'eat', 'lunch'): 1, ('chinese', 'food', 'i'): 1, ('want', 'chinese', 'i'): 2, ('chinese', 'i', 'want'): 2}\n",
            "\n",
            "Trigrams change our calculations greatly. We have completely different probabilities, because we are including an entire extra string.\n",
            "This change has dropped down the frequency of words occuring together.\n"
          ]
        }
      ]
    }
  ]
}
